---
title: "Etapa2_Equipo5"
author: "Miguel Angel González Gutiérrez"
date: "2025-10-10"
output: pdf_document
---

## Retomar Etapa I

### Data Load
```{r}
Estaciones<- c(
  "SURESTE",
  "NORESTE",
  "CENTRO",
  "NOROESTE",
  "SUROESTE",
  "NOROESTE 2",
  "NORTE",
  "NORESTE2",
  "SURESTE2",
  "SUROESTE2",
  "SUR",
  "NORTE 2",
  "SURESTE 3",
  "NOROESTE 3",
  "NORESTE 3"
)
```


```{r}
library(readxl)
for (est in Estaciones) {
  assign(est, read_excel(
    "DATOS_COMBINADOS_2023_2024_COMPLETO.xlsx",
    sheet = est,
    na = "NULL",
    guess_max = 100000
  ))
}
```

```{r}
VARIABLES <- c(
  "fecha",
  "O3 (ppb)",
  "NO2 (ppb)",
  "PM2.5 (ug/m3)",
  "PM10 (ug/m3)",
  "TOUT (ºC)",
  "RH (%)",
  "RAINF (mm/h)",
  "SR (kW/m2)",
  "WSR (km/h)",
  "WDR (azimutal)"
)
```


```{r}
for (est in Estaciones) {
    df <- get(est)  # obtener el data frame por nombre
    df <- df[, intersect(names(df), VARIABLES)]  # conservar solo las columnas coincidentes
    assign(est, df)
}
```


```{r}
cat("Porcentajes de datos faltantes a imputar:\n")

for (est in Estaciones) {
    df <- get(est)
    pct_na <- sum(is.na(df)) / (nrow(df) * ncol(df)) * 100
    cat(est, ": ", round(pct_na, 2), "%\n", sep = "")
  }
```

FUNCION DE IMPUTACION

```{r}
library(mice)
library(imputeTS)


imputar_series_tiempo <- function(datos, metodo = "kalman") {
  
  #Filtrar para aplicar imputacion exceptuando la columna de fecha
  datos_sin_fechas <- datos[, -1]
  
  # Asegurar nombres válidos
  names(datos_sin_fechas) <- make.names(names(datos_sin_fechas))
  
  # Convertir datos_sin_fechas a formato ts si no lo está
  if (!is.ts(datos_sin_fechas)) {
    datos_sin_fechas <- as.ts(datos_sin_fechas)
  }
  
  # Verificar el método de imputación solicitado
  metodo <- match.arg(metodo, c("kalman", "arima", "interpolacion", "mice"))
  
  datos_imputados <- switch(metodo,
    "kalman" = {
      # Imputación usando filtro Kalman
      datos_imp <- na_kalman(datos, model = "auto.arima")
    },
    "arima" = {
      # Imputación usando ARIMA
      datos_imp <- na_seadec(datos, algorithm = "arima", find_frequency = TRUE)
    },
    "interpolacion" = {
      # Imputación usando interpolación
      datos_imp <- na_interpolation(datos, option = "spline")
    },
    "mice" = {
      datos_mids <- mice(as.data.frame(datos_sin_fechas), m = 5, maxit = 10, printFlag = FALSE)
      datos_imp <- complete(datos_mids)
    }
  )
  
  datos_final <- as.data.frame(datos_imp)
  
  
  return(datos_final)
}

# Función para evaluar la calidad de la imputación
evaluar_imputacion <- function(datos_originales, datos_imputados) {
  # Convertir ambos conjuntos de datos a matrices
  if (is.data.frame(datos_originales)) datos_originales <- as.matrix(datos_originales)
  if (is.data.frame(datos_imputados)) datos_imputados <- as.matrix(datos_imputados)
  
  # Calcular métricas de error solo para valores no NA en los datos originales
  mascara_na <- is.na(datos_originales)
  
  # Calcular RMSE y MAE solo para valores imputados
  errores <- list()
  for (col in 1:ncol(datos_originales)) {
    valores_orig <- datos_originales[!mascara_na[,col], col]
    valores_imp <- datos_imputados[!mascara_na[,col], col]
    
    rmse <- sqrt(mean((valores_orig - valores_imp)^2))
    mae <- mean(abs(valores_orig - valores_imp))
    
    errores[[colnames(datos_originales)[col]]] <- list(
      RMSE = rmse,
      MAE = mae
    )
  }
  
  return(errores)
}
```


```{r}
for (est in Estaciones) {
    df <- get(est)  # obtener el data.frame
    df_imputado <- imputar_series_tiempo(df, metodo = "mice")  # imputar
    assign(est, df_imputado)  # Reemplazar el data.frame original con el imputado
    cat("✅ Imputación completada para:", est, "\n")
  }
```


```{r}
cat("Porcentajes de datos faltantes a imputar:\n")

for (est in Estaciones) {
    df <- get(est)
    pct_na <- sum(is.na(df)) / (nrow(df) * ncol(df)) * 100
    cat(est, ": ", round(pct_na, 2), "%\n", sep = "")
  }
```
NO2
NO3
SE3
SE2
```{r}
Estaciones<- c(
  "CENTRO",
  "SUR"
)
```

Decidimos borrarlas por practicidad del análisis. Se abordaran estaciones estratégicas que se encuentren dentro de zonas residenciales. El análisis buscará resultados enfocándose en estas áreas.

```{r}
library(openxlsx)

# Crear un nuevo workbook
wb <- createWorkbook()

# Recorrer cada estación y agregar como hoja
for (est in Estaciones) {
    df <- get(est)    # obtener el data.frame
    addWorksheet(wb, sheetName = est)  # crear hoja con el nombre de la estación
    writeData(wb, sheet = est, df)    # escribir los datos en la hoja
  }

# Guardar el archivo Excel
saveWorkbook(wb, file = "DATOS_ESTACIONES_COMPLETOS.xlsx", overwrite = TRUE)

cat("✅ Archivo Excel generado: DATOS_ESTACIONES_COMPLETOS.xlsx\n")
```


Una vez ya imputados los datos, se procederá a realizar el análisis descriptivo de las variables.

```{r}
Estaciones <- c("CENTRO", "SUR")

for (est in Estaciones) {
  cat("\n\n===== Estación:", est, "=====\n")
  
  df <- get(est)
  
  for (var in names(df)) {
    x <- df[[var]]
    
    cat("\nVariable:", var, "\n")
    
    if (is.numeric(x)) {
      cat("Media:", mean(x, na.rm = TRUE), "\n")
      cat("Mediana:", median(x, na.rm = TRUE), "\n")
      cat("Moda:", names(sort(table(x), decreasing = TRUE))[1], "\n")

    }
  }
}

```

```{r}
# Vector con los nombres de tus dataframes
Estaciones <- c("CENTRO", "SUR")

for (est in Estaciones) {
  cat("\n\n===== Estación:", est, "=====\n")
  
  df <- get(est)  # obtiene el dataframe con ese nombre
  
  for (var in names(df)) {
    x <- df[[var]]
    
    # Solo calcular si la variable es numérica
    if (is.numeric(x)) {
      cat("\nVariable:", var, "\n")
      
      # --- Medidas de dispersión ---
      maximo <- max(x, na.rm = TRUE)
      minimo <- min(x, na.rm = TRUE)
      rango <- maximo - minimo
      varianza <- var(x, na.rm = TRUE)
      desviacion <- sd(x, na.rm = TRUE)
      
      cat("Máximo:", maximo, "\n")
      cat("Mínimo:", minimo, "\n")
      cat("Rango (Máx - Mín):", rango, "\n")
      cat("Varianza:", varianza, "\n")
      cat("Desviación estándar:", desviacion, "\n")
      
    } else {
      cat("\nVariable:", var, "\n")
      cat("(No aplica: variable cualitativa)\n")
    }
  }
}

```



```{r}
# Vector con nombres de tus dataframes
Estaciones <- c("CENTRO", "SUR")

for (est in Estaciones) {
  df <- get(est)  # obtiene el dataframe
  
  cat("\nGenerando boxplots para la estación:", est, "\n")
  
  # Filtrar solo las variables numéricas
  df_num <- df[, sapply(df, is.numeric)]
  
  # Crear un gráfico de cajas para todas las variables numéricas de la estación
  if (ncol(df_num) > 0) {
    boxplot(df_num,
            main = paste("Boxplots de variables - Estación", est),
            col = "lightblue",
            las = 2,         # nombres de variables en vertical
            cex.axis = 0.8)  # tamaño de etiquetas del eje x
  } else {
    cat("No hay variables numéricas en la estación", est, "\n")
  }
}
```


```{r}
# Vector con nombres de tus dataframes
Estaciones <- c("CENTRO", "SUR")

for (est in Estaciones) {
  df <- get(est)
  df_num <- df[, sapply(df, is.numeric)]
  
  if (ncol(df_num) > 0) {
    # Definir el número de gráficos por fila y columna
    num_vars <- ncol(df_num)
    n_cols <- ceiling(sqrt(num_vars))   # columnas según cantidad de variables
    n_rows <- ceiling(num_vars / n_cols)
    
    # Configurar la cuadrícula de gráficos
    par(mfrow = c(n_rows, n_cols))
    par(mar = c(4, 4, 2, 1))  # márgenes
    
    # Generar un histograma por variable
    for (var in names(df_num)) {
      hist(df_num[[var]],
           main = paste(est, "-", var),
           xlab = var,
           ylab = "Frecuencia",
           col = "lightblue",
           border = "gray",
           breaks = 15)
    }
    
    # Título general para la estación
    mtext(paste(est),
          outer = TRUE, cex = 1.5, line = -1.5)
    
    # Restaurar configuración gráfica original
    par(mfrow = c(1,1))
  }
}
```

```{r}
library(ggcorrplot)

for (est in Estaciones) {
  df <- get(est)
  
  # Seleccionar solo variables numéricas
  df_num <- df[, sapply(df, is.numeric)]
  
  if (ncol(df_num) > 1) {  # al menos 2 variables para correlación
    # Calcular la matriz de correlación
    Corr <- cor(df_num, use = "pairwise.complete.obs")
    
    # Crear el mapa de calor y guardarlo en un objeto
    p <- ggcorrplot(Corr,
                    hc.order = TRUE,
                    type = "lower",
                    lab = TRUE,
                    lab_size = 3,
                    colors = c("blue", "white", "red"),
                    title = paste("Mapa de calor de correlaciones - Estación", est))
    
    # Imprimir explícitamente el gráfico
    print(p)
  }
}

```

```{r}
library(lubridate)
library(dplyr)

# Crear la secuencia de fechas completa
fechas_completas <- seq(
  from = ymd_h("2023-01-01 00"),
  to   = ymd_h("2024-12-31 23"),
  by   = "1 hour"
)

length(fechas_completas)  # 17544

# Si tus df tienen 17542 filas, recortamos a ese tamaño
fechas_recortadas <- fechas_completas[1:nrow(CENTRO)]

# Asignar directamente (sin join)
CENTRO <- CENTRO %>% mutate(fecha_hora = fechas_recortadas)
SUR    <- SUR %>% mutate(fecha_hora = fechas_recortadas)

```
```{r}
CENTRO_dif <- CENTRO %>%
  mutate(fecha = as.Date(fecha_hora)) %>%
  group_by(fecha) %>%
  summarise(
    temp_max = max(`TOUT..ºC.`, na.rm = TRUE),
    temp_min = min(`TOUT..ºC.`, na.rm = TRUE),
    dif_temp = temp_max - temp_min
  ) %>%
  ungroup()

```

```{r}
library(ggplot2)

ggplot(CENTRO_dif, aes(x = fecha, y = dif_temp)) +
  geom_line(color = "steelblue") +
  geom_smooth(color = "red", se = FALSE) +
  labs(title = "Diferencia diaria de temperatura (máx - mín)",
       x = "Fecha", y = "Δ Temperatura (°C)") +
  theme_minimal()

```

```{r}
SUR_dif <- SUR %>%
  mutate(fecha = as.Date(fecha_hora)) %>%
  group_by(fecha) %>%
  summarise(
    temp_max = max(`TOUT..ºC.`, na.rm = TRUE),
    temp_min = min(`TOUT..ºC.`, na.rm = TRUE),
    dif_temp = temp_max - temp_min
  ) %>%
  ungroup()

```

```{r}
library(ggplot2)

ggplot(SUR_dif, aes(x = fecha, y = dif_temp)) +
  geom_line(color = "steelblue") +
  geom_smooth(color = "red", se = FALSE) +
  labs(title = "Diferencia diaria de temperatura (máx - mín)",
       x = "Fecha", y = "Δ Temperatura (°C)") +
  theme_minimal()

```
```{r}
summary(SUR_dif$dif_temp)
```


```{r}
cat("RADIACION: \n")
summary(CENTRO$SR..kW.m2.)
cat("\n\nViento:\n")
summary(CENTRO$WSR..km.h.)
```
```{r}
cat("RADIACION: \n")
summary(SUR$SR..kW.m2.)
cat("\n\nViento:\n")
summary(SUR$WSR..km.h.)
```

```{r}
library(dplyr)
library(lubridate)

# 1️⃣ Extraer fecha
CENTRO <- CENTRO %>%
  mutate(fecha = as.Date(fecha_hora))

# 2️⃣ Calcular ΔT diario, min radiación, min viento
CENTRO_dia <- CENTRO %>%
  group_by(fecha) %>%
  summarise(
    dif_temp = max(`TOUT..ºC.`, na.rm = TRUE) - min(`TOUT..ºC.`, na.rm = TRUE),
    min_radiacion = min(`SR..kW.m2.`, na.rm = TRUE),
    min_viento = min(`WSR..km.h.`, na.rm = TRUE)
  ) %>%
  ungroup()

# 3️⃣ Umbral de ΔT
umbral_difT <- quantile(CENTRO_dia$dif_temp, 0.75, na.rm = TRUE)

# 4️⃣ Crear columna binaria de inversión
CENTRO_dia <- CENTRO_dia %>%
  mutate(INVERSION = ifelse(
    dif_temp > umbral_difT & min_radiacion < 0.15 & min_viento < 7.2,
    1, 0
  ))

# 5️⃣ Asignar la inversión al día siguiente usando lag
CENTRO_dia <- CENTRO_dia %>%
  mutate(INVERSION_SIG = lag(INVERSION, n = 1, default = 0))

# 6️⃣ Combinar con df original mediante match de fecha (sin join pesado)
CENTRO <- CENTRO %>%
  left_join(CENTRO_dia %>% select(fecha, INVERSION_SIG),
            by = "fecha") %>%
  rename(INVERSION = INVERSION_SIG) %>%
  mutate(INVERSION = ifelse(is.na(INVERSION), 0, INVERSION))

```

```{r}
table(CENTRO$INVERSION)
```
```{r}
# 1️⃣ Extraer fecha
SUR <- SUR %>%
  mutate(fecha = as.Date(fecha_hora))

# 2️⃣ Calcular ΔT diario, min radiación, min viento
SUR_dia <- SUR %>%
  group_by(fecha) %>%
  summarise(
    dif_temp = max(`TOUT..ºC.`, na.rm = TRUE) - min(`TOUT..ºC.`, na.rm = TRUE),
    min_radiacion = min(`SR..kW.m2.`, na.rm = TRUE),
    min_viento = min(`WSR..km.h.`, na.rm = TRUE)
  ) %>%
  ungroup()

# 3️⃣ Umbral de ΔT
umbral_difT <- quantile(SUR_dia$dif_temp, 0.75, na.rm = TRUE)

# 4️⃣ Crear columna binaria de inversión
SUR_dia <- SUR_dia %>%
  mutate(INVERSION = ifelse(
    dif_temp > umbral_difT & min_radiacion < 0.15 & min_viento < 7.2,
    1, 0
  ))

# 5️⃣ Asignar la inversión al día siguiente usando lag
SUR_dia <- SUR_dia %>%
  mutate(INVERSION_SIG = lag(INVERSION, n = 1, default = 0))

# 6️⃣ Combinar con df original mediante match de fecha (sin join pesado)
SUR <- SUR %>%
  left_join(SUR_dia %>% select(fecha, INVERSION_SIG),
            by = "fecha") %>%
  rename(INVERSION = INVERSION_SIG) %>%
  mutate(INVERSION = ifelse(is.na(INVERSION), 0, INVERSION))
```

```{r}
table(SUR$INVERSION)
```











